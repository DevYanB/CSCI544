{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVYAN BISWAS HOMEWORK 2 REPORT\n",
    "---\n",
    "- python version 3.7.5\n",
    "- addtl reference: https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.tsv', sep='\\t', usecols = ['star_rating','review_body'], header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['star_rating'].isin([5, 4, 3, 2, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767046</th>\n",
       "      <td>4</td>\n",
       "      <td>It is nice looking and everything (it is sterl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767047</th>\n",
       "      <td>4</td>\n",
       "      <td>my boyfriend bought me this last christmas, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767048</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a great way to quickly start learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767049</th>\n",
       "      <td>5</td>\n",
       "      <td>the 14kt gold earrings look remarkable...would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767050</th>\n",
       "      <td>5</td>\n",
       "      <td>It will be a gift to my special friend. We kno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1701275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "0                 5  so beautiful even tho clearly not high end ......\n",
       "1                 5  Great product.. I got this set for my mother, ...\n",
       "2                 5  Exactly as pictured and my daughter's friend l...\n",
       "3                 5  Love it. Fits great. Super comfortable and nea...\n",
       "4                 5  Got this as a Mother's Day gift for my Mom and...\n",
       "...             ...                                                ...\n",
       "1767046           4  It is nice looking and everything (it is sterl...\n",
       "1767047           4  my boyfriend bought me this last christmas, an...\n",
       "1767048           4  This is a great way to quickly start learning ...\n",
       "1767049           5  the 14kt gold earrings look remarkable...would...\n",
       "1767050           5  It will be a gift to my special friend. We kno...\n",
       "\n",
       "[1701275 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['star_rating'] = df['star_rating'].astype(int)\n",
    "# df['review_body'] = df['review_body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "df['review_body']  = df['review_body'].str.replace(r's*https?://S+(s+|$)', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].astype(str)\n",
    "df['review_body'] = df['review_body'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df.review_body.str.replace('[^a-zA-Z\\s]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].replace('', np.nan)\n",
    "df['review_body'] = df['review_body'].replace(' ', np.nan)\n",
    "df['review_body'] = df['review_body'].replace('nan', np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>so beautiful even though clearly not high end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>great product i got this set for my mother as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>exactly as pictured and my daughter s friend l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>love it fits great super comfortable and neat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>got this as a mother s day gift for my mom and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767046</th>\n",
       "      <td>4</td>\n",
       "      <td>it is nice looking and everything it is sterli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767047</th>\n",
       "      <td>4</td>\n",
       "      <td>my boyfriend bought me this last christmas and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767048</th>\n",
       "      <td>4</td>\n",
       "      <td>this is a great way to quickly start learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767049</th>\n",
       "      <td>5</td>\n",
       "      <td>the kt gold earrings look remarkable would def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767050</th>\n",
       "      <td>5</td>\n",
       "      <td>it will be a gift to my special friend we know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5  so beautiful even though clearly not high end ...\n",
       "1                  5  great product i got this set for my mother as ...\n",
       "2                  5  exactly as pictured and my daughter s friend l...\n",
       "3                  5  love it fits great super comfortable and neat ...\n",
       "4                  5  got this as a mother s day gift for my mom and...\n",
       "...              ...                                                ...\n",
       "1767046            4  it is nice looking and everything it is sterli...\n",
       "1767047            4  my boyfriend bought me this last christmas and...\n",
       "1767048            4  this is a great way to quickly start learning ...\n",
       "1767049            5  the kt gold earrings look remarkable would def...\n",
       "1767050            5  it will be a gift to my special friend we know...\n",
       "\n",
       "[1700118 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the 20k of each rating type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_5_df = df[df['star_rating'] == 5]\n",
    "star_4_df = df[df['star_rating'] == 4]\n",
    "star_3_df = df[df['star_rating'] == 3]\n",
    "star_2_df = df[df['star_rating'] == 2]\n",
    "star_1_df = df[df['star_rating'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSING 20k random entries from each\n",
    "# Seeding them so that data is more consistent\n",
    "df_20_5 = star_5_df.sample(n=20000, random_state=100)\n",
    "df_20_4 = star_4_df.sample(n=20000, random_state=100)\n",
    "df_20_3 = star_3_df.sample(n=20000, random_state=100)\n",
    "df_20_2 = star_2_df.sample(n=20000, random_state=100)\n",
    "df_20_1 = star_1_df.sample(n=20000, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting them 16k and 4k to make new datasets for training and testing\n",
    "training_5 = df_20_5.iloc[:16000,:]\n",
    "testing_5 = df_20_5.iloc[16000:,:]\n",
    "training_4 = df_20_4.iloc[:16000,:]\n",
    "testing_4 = df_20_4.iloc[16000:,:]\n",
    "training_3 = df_20_3.iloc[:16000,:]\n",
    "testing_3 = df_20_3.iloc[16000:,:]\n",
    "training_2 = df_20_2.iloc[:16000,:]\n",
    "testing_2 = df_20_2.iloc[16000:,:]\n",
    "training_1 = df_20_1.iloc[:16000,:]\n",
    "testing_1 = df_20_1.iloc[16000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the ones above into one dataframe for training\n",
    "# training_data = [training_5, training_4, training_3, training_2, training_1]\n",
    "training_data = pd.concat([training_5, training_4])\n",
    "training_data = pd.concat([training_data, training_3])\n",
    "training_data = pd.concat([training_data, training_2])\n",
    "training_data = pd.concat([training_data, training_1])\n",
    "training_data=training_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the remaining ones above into one dataframe for testing\n",
    "testing_data = pd.concat([testing_5, testing_4])\n",
    "testing_data = pd.concat([testing_data, testing_3])\n",
    "testing_data = pd.concat([testing_data, testing_2])\n",
    "testing_data = pd.concat([testing_data, testing_1])\n",
    "testing_data=testing_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = pd.concat([training_data, testing_data])\n",
    "whole_dataset=whole_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>this is my third set purchased from them and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>great little reminder just have faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>works well with black ceramic watch and other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>great necklace the amount of bling is perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>the glass beads are very pretty it did come a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>very cheap looking looks like costume jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>the bracelet had a very musty smell that i cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>i cannot get them in my piercing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>did not like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>this bracelet is crap the lock sucks complete a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating                                        review_body\n",
       "0                5  this is my third set purchased from them and i...\n",
       "1                5             great little reminder just have faith \n",
       "2                5  works well with black ceramic watch and other ...\n",
       "3                5  great necklace the amount of bling is perfect ...\n",
       "4                5  the glass beads are very pretty it did come a ...\n",
       "...            ...                                                ...\n",
       "99995            1      very cheap looking looks like costume jewelry\n",
       "99996            1  the bracelet had a very musty smell that i cou...\n",
       "99997            1                   i cannot get them in my piercing\n",
       "99998            1                                       did not like\n",
       "99999            1   this bracelet is crap the lock sucks complete a \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        this is my third set purchased from them and i...\n",
       "1                   great little reminder just have faith \n",
       "2        works well with black ceramic watch and other ...\n",
       "3        great necklace the amount of bling is perfect ...\n",
       "4        the glass beads are very pretty it did come a ...\n",
       "                               ...                        \n",
       "99995        very cheap looking looks like costume jewelry\n",
       "99996    the bracelet had a very musty smell that i cou...\n",
       "99997                     i cannot get them in my piercing\n",
       "99998                                         did not like\n",
       "99999     this bracelet is crap the lock sucks complete a \n",
       "Name: review_body, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_reviews = whole_dataset['review_body']\n",
    "only_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data.to_csv('test.csv', index=False) \n",
    "training_data.to_csv('train.csv', index=False) \n",
    "whole_dataset.to_csv('whole_dataset.csv', index=False) \n",
    "only_reviews.to_csv('only_reviews.csv', index=False, header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM HERE ON OUT we do not need to run anything before; just gotta read from our friends test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, getting the google news word2vec model and testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec = gensim_api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wordvec.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wordvec.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 tests for semantic similarity and the like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cosine_sim(a, b):\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def e_dist(a,b):\n",
    "    return np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and bracelet:  3.9348783  vs Euclidean dist of test_vec and anklet:  4.7187786\n",
      "Cosine Similarity of test_vec and bracelet:  0.60587525  vs cosine sim of test_vec and anklet:  0.4625539\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 1\n",
    "necklace = wordvec['necklace']\n",
    "neck = wordvec['neck']\n",
    "wrist = wordvec['wrist']\n",
    "bracelet = wordvec['bracelet']\n",
    "anklet = wordvec['anklet']\n",
    "vec_test = (necklace - neck) + wrist\n",
    "\n",
    "#Euclidean distance comparison\n",
    "edist = e_dist(vec_test, bracelet)\n",
    "edist_t = e_dist(vec_test, anklet)\n",
    "cosine_sim = np_cosine_sim(vec_test, bracelet)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, anklet)\n",
    "print(\"Euclidean distance of test_vec and bracelet: \", edist, \" vs Euclidean dist of test_vec and anklet: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and bracelet: \", cosine_sim ,\" vs cosine sim of test_vec and anklet: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and son:  1.1582639  vs Euclidean dist of test_vec and brother:  2.0276282\n",
      "Cosine Similarity of test_vec and son:  0.91892457  vs cosine sim of test_vec and brother:  0.74743086\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 2\n",
    "daughter = wordvec['daughter']\n",
    "son = wordvec['son']\n",
    "brother = wordvec['brother']\n",
    "boy = wordvec['boy']\n",
    "girl = wordvec['girl']\n",
    "vec_test = (daughter - girl) + boy\n",
    "\n",
    "#Euclidean distance comparison\n",
    "edist = e_dist(vec_test, son)\n",
    "edist_t = e_dist(vec_test, brother)\n",
    "cosine_sim = np_cosine_sim(vec_test, son)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, brother)\n",
    "print(\"Euclidean distance of test_vec and son: \", edist, \" vs Euclidean dist of test_vec and brother: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and son: \", cosine_sim ,\" vs cosine sim of test_vec and brother: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and earring:  5.6522703  vs Euclidean dist of test_vec and necklace:  5.812169\n",
      "Cosine Similarity of test_vec and earring:  0.3556472  vs cosine sim of test_vec and necklace:  0.31888828\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 3\n",
    "ring = wordvec['ring']\n",
    "finger = wordvec['finger']\n",
    "ear = wordvec['ear']\n",
    "earring = wordvec['earring']\n",
    "necklace = wordvec['necklace']\n",
    "piercing = wordvec['piercing']\n",
    "vec_test = (ring - finger) + piercing + ear\n",
    "\n",
    "\n",
    "edist = e_dist(vec_test, earring)\n",
    "edist_t = e_dist(vec_test, necklace)\n",
    "cosine_sim = np_cosine_sim(vec_test, earring)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, necklace)\n",
    "print(\"Euclidean distance of test_vec and earring: \", edist, \" vs Euclidean dist of test_vec and necklace: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and earring: \", cosine_sim ,\" vs cosine sim of test_vec and necklace: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the two examples above, each vector is closer/more similar to the vector it's intended to be for \n",
    "<br>\n",
    "over another control vector. This shows the basic functionality of word2vec and its usefulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we want to train a model with our own dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX THIS: ONLY HAVE SENTENCES NOT THE OTHER NONSENSE BROH\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('/Users/devyanbiswas/Desktop/CSCI544/Homeworks/HW2/only_reviews.csv')\n",
    "        for line in open(corpus_path):\n",
    "            # print(line)\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, window=11, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these out with our examples from above (yes it's copy and pasted but this is what i can do rn lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and bracelet:  12.631125  vs Euclidean dist of test_vec and anklet:  19.925135\n",
      "Cosine Similarity of test_vec and bracelet:  0.8182945  vs cosine sim of test_vec and anklet:  0.46293825\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 1\n",
    "necklace = model.wv['necklace']\n",
    "neck = model.wv['neck']\n",
    "wrist = model.wv['wrist']\n",
    "bracelet = model.wv['bracelet']\n",
    "anklet = model.wv['anklet']\n",
    "vec_test = (necklace - neck) + wrist\n",
    "\n",
    "#Euclidean distance comparison\n",
    "edist = e_dist(vec_test, bracelet)\n",
    "edist_t = e_dist(vec_test, anklet)\n",
    "cosine_sim = np_cosine_sim(vec_test, bracelet)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, anklet)\n",
    "print(\"Euclidean distance of test_vec and bracelet: \", edist, \" vs Euclidean dist of test_vec and anklet: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and bracelet: \", cosine_sim ,\" vs cosine sim of test_vec and anklet: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and son:  17.356606  vs Euclidean dist of test_vec and brother:  16.919842\n",
      "Cosine Similarity of test_vec and son:  0.45576268  vs cosine sim of test_vec and brother:  0.34291872\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 2\n",
    "daughter = model.wv['daughter']\n",
    "son = model.wv['son']\n",
    "brother = model.wv['brother']\n",
    "boy = model.wv['boy']\n",
    "girl = model.wv['girl']\n",
    "vec_test = (daughter - girl) + boy\n",
    "\n",
    "#Euclidean distance comparison\n",
    "edist = e_dist(vec_test, son)\n",
    "edist_t = e_dist(vec_test, brother)\n",
    "cosine_sim = np_cosine_sim(vec_test, son)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, brother)\n",
    "print(\"Euclidean distance of test_vec and son: \", edist, \" vs Euclidean dist of test_vec and brother: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and son: \", cosine_sim ,\" vs cosine sim of test_vec and brother: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance of test_vec and earring:  27.762281  vs Euclidean dist of test_vec and necklace:  38.68862\n",
      "Cosine Similarity of test_vec and earring:  0.6088801  vs cosine sim of test_vec and necklace:  0.003107671\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 3\n",
    "ring = model.wv['ring']\n",
    "finger = model.wv['finger']\n",
    "ear = model.wv['ear']\n",
    "earring = model.wv['earring']\n",
    "necklace = model.wv['necklace']\n",
    "piercing = model.wv['piercing']\n",
    "vec_test = (ring - finger) + piercing + ear\n",
    "\n",
    "\n",
    "edist = e_dist(vec_test, earring)\n",
    "edist_t = e_dist(vec_test, necklace)\n",
    "cosine_sim = np_cosine_sim(vec_test, earring)\n",
    "cosine_sim_t = np_cosine_sim(vec_test, necklace)\n",
    "print(\"Euclidean distance of test_vec and earring: \", edist, \" vs Euclidean dist of test_vec and necklace: \", edist_t)\n",
    "print(\"Cosine Similarity of test_vec and earring: \", cosine_sim ,\" vs cosine sim of test_vec and necklace: \" , cosine_sim_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosime similarity scores are consistently better for the specific model, and euclidean distances are also more or less\n",
    "<br>\n",
    "better, but there is an error in example 2 (the dist of the test_vec and brother is slightly closer than that of it and son).\n",
    "<br>\n",
    "Other than that, it actually seems that in terms of semantic similarity, our specific model does better at modeling relationships\n",
    "<br>\n",
    "given the difference in the two measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that being said, let's move onto the simple models with training from Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we're gonna train a perceptron and an SVM model on the pre-trained google W2V data\n",
    "<br>\n",
    "First, let's develop the \"average vector\" for each review, which is described as:\n",
    "<br>\n",
    "$\\frac{1}{N}\\sum_{i=1}^{N} W_i$ with N words in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing testing and training data, splitting them into appropriate X and y pairs as well\n",
    "train = pd.read_csv('./train.csv', header=0)\n",
    "test = pd.read_csv('./test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>this is my third set purchased from them and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>great little reminder just have faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>works well with black ceramic watch and other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>great necklace the amount of bling is perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>the glass beads are very pretty it did come a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>1</td>\n",
       "      <td>wore it once still covered in an itchy red ras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1</td>\n",
       "      <td>this ring arrived in timely fashion which i li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1</td>\n",
       "      <td>poorly made and combined good thing is i am cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1</td>\n",
       "      <td>this came late and broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>1</td>\n",
       "      <td>i was happy to find these and was going to wea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating                                        review_body\n",
       "0                5  this is my third set purchased from them and i...\n",
       "1                5             great little reminder just have faith \n",
       "2                5  works well with black ceramic watch and other ...\n",
       "3                5  great necklace the amount of bling is perfect ...\n",
       "4                5  the glass beads are very pretty it did come a ...\n",
       "...            ...                                                ...\n",
       "79995            1  wore it once still covered in an itchy red ras...\n",
       "79996            1  this ring arrived in timely fashion which i li...\n",
       "79997            1  poorly made and combined good thing is i am cr...\n",
       "79998            1                         this came late and broken \n",
       "79999            1  i was happy to find these and was going to wea...\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanEmbeddings(model, sentence):\n",
    "        words = sentence.split()\n",
    "        # remove out-of-vocabulary words\n",
    "        words = [word for word in words if word in model]\n",
    "        if len(words) >= 1:\n",
    "            return np.mean(model[words], axis=0)\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['review_body'] = train.apply(lambda x: meanEmbeddings(wordvec, x['review_body']), axis=1)\n",
    "test['review_body'] = test.apply(lambda x: meanEmbeddings(wordvec, x['review_body']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an issue: some embeddings are just empty. So for now, instead of doing the training/testing data split here so that\n",
    "<br>\n",
    "we have the full 80k/20k split, im gonna just drop empty vectors.\n",
    "TODO: Do the splitting _AFTER_ you drop empty list embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['review_body'].map(lambda d: len(d)) > 0]\n",
    "test = test[test['review_body'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reset_index(drop=True)\n",
    "test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.021781074, 0.010730558, 0.03842163, 0.09902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.0777181, 0.0241038, -0.003133138, 0.1139322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.03963216, 0.0152542675, 0.009416086, 0.0662...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.0351429, 0.040046692, 0.016231537, 0.068573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.022198932, 0.0065338784, -0.010754097, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79950</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.040590923, 0.019532362, 0.06068675, 0.08143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79951</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.008141665, 0.013809791, 0.024548898, 0.0918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79952</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.01965768, -0.007548264, 0.051713128, 0.0990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79953</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.049072266, 0.12234497, 0.024169922, 0.03753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.041787915, 0.051063508, 0.029582731, 0.1004...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating                                        review_body\n",
       "0                5  [0.021781074, 0.010730558, 0.03842163, 0.09902...\n",
       "1                5  [0.0777181, 0.0241038, -0.003133138, 0.1139322...\n",
       "2                5  [0.03963216, 0.0152542675, 0.009416086, 0.0662...\n",
       "3                5  [0.0351429, 0.040046692, 0.016231537, 0.068573...\n",
       "4                5  [0.022198932, 0.0065338784, -0.010754097, 0.10...\n",
       "...            ...                                                ...\n",
       "79950            1  [0.040590923, 0.019532362, 0.06068675, 0.08143...\n",
       "79951            1  [0.008141665, 0.013809791, 0.024548898, 0.0918...\n",
       "79952            1  [0.01965768, -0.007548264, 0.051713128, 0.0990...\n",
       "79953            1  [0.049072266, 0.12234497, 0.024169922, 0.03753...\n",
       "79954            1  [0.041787915, 0.051063508, 0.029582731, 0.1004...\n",
       "\n",
       "[79955 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.018040033, 0.043087665, 0.03163665, 0.12524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.015490723, 0.08129883, 0.031079102, 0.10883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.01468811, -0.040407658, -0.012677002, 0.150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.032828193, 0.000926154, 0.06468855, 0.0201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.02191816, 0.023200626, 0.04187157, 0.096947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.011849539, 0.0987636, -0.065767564, 0.11478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.016875131, -0.010713373, 0.034745354, 0.113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.026611328, 0.039376397, 0.057128906, 0.1531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.1295573, 0.065592445, 0.07306417, 0.1007080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.018993378, -0.04724121, 0.009490967, 0.1369...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating                                        review_body\n",
       "0                5  [0.018040033, 0.043087665, 0.03163665, 0.12524...\n",
       "1                5  [0.015490723, 0.08129883, 0.031079102, 0.10883...\n",
       "2                5  [0.01468811, -0.040407658, -0.012677002, 0.150...\n",
       "3                5  [-0.032828193, 0.000926154, 0.06468855, 0.0201...\n",
       "4                5  [0.02191816, 0.023200626, 0.04187157, 0.096947...\n",
       "...            ...                                                ...\n",
       "19983            1  [0.011849539, 0.0987636, -0.065767564, 0.11478...\n",
       "19984            1  [0.016875131, -0.010713373, 0.034745354, 0.113...\n",
       "19985            1  [0.026611328, 0.039376397, 0.057128906, 0.1531...\n",
       "19986            1  [0.1295573, 0.065592445, 0.07306417, 0.1007080...\n",
       "19987            1  [0.018993378, -0.04724121, 0.009490967, 0.1369...\n",
       "\n",
       "[19988 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(train['review_body'].to_list())\n",
    "train_y = train['star_rating']\n",
    "\n",
    "test_X = pd.DataFrame(test['review_body'].to_list())\n",
    "test_y = test['star_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Training and Metrics\n",
    "- Gonna compare these to HW1 metrics, which will be imported in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perc = Perceptron()\n",
    "perc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS FOR PERCEPTRON\n",
      "======================\n",
      "Recall Avg:  0.40106992135312886\n",
      "Accuracy Avg:  0.400990594356614\n",
      "HW1 Accuracy:  0.41665\n",
      "Precision Avg:  0.4499730442232609\n",
      "F1 Avg:  0.3678551740823453\n"
     ]
    }
   ],
   "source": [
    "# Testing and score calcs\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "perc_y_pred = perc.predict(test_X)\n",
    "\n",
    "print(\"METRICS FOR PERCEPTRON\")\n",
    "print(\"======================\")\n",
    "\n",
    "# Averages\n",
    "recall_avg = recall_score(test_y, perc_y_pred, average='macro')\n",
    "accuracy_avg = accuracy_score(test_y, perc_y_pred)\n",
    "precision_avg = precision_score(test_y, perc_y_pred, average='macro')\n",
    "f1_avg = f1_score(test_y, perc_y_pred, average='macro')\n",
    "\n",
    "print(\"Recall Avg: \", recall_avg)\n",
    "print(\"Accuracy Avg: \", accuracy_avg)\n",
    "print(\"HW1 Accuracy: \", 0.41665)\n",
    "print(\"Precision Avg: \", precision_avg)\n",
    "print(\"F1 Avg: \", f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=2000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lin_svc = LinearSVC(max_iter=2000)\n",
    "lin_svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS FOR SVC\n",
      "======================\n",
      "Recall Avg:  0.48418447370576717\n",
      "Accuracy Avg:  0.48409045427256353\n",
      "HW1 Accuracy:  0.4849\n",
      "Precision Avg:  0.46487209033571564\n",
      "F1 Avg:  0.4646735269946672\n"
     ]
    }
   ],
   "source": [
    "svc_pred = lin_svc.predict(test_X)\n",
    "\n",
    "print(\"METRICS FOR SVC\")\n",
    "print(\"======================\")\n",
    "\n",
    "# Averages\n",
    "recall_avg = recall_score(test_y, svc_pred, average='macro')\n",
    "accuracy_avg = accuracy_score(test_y, svc_pred)\n",
    "precision_avg = precision_score(test_y, svc_pred, average='macro')\n",
    "f1_avg = f1_score(test_y, svc_pred, average='macro')\n",
    "\n",
    "print(\"Recall Avg: \", recall_avg)\n",
    "print(\"Accuracy Avg: \", accuracy_avg)\n",
    "print(\"HW1 Accuracy: \", 0.4849)\n",
    "print(\"Precision Avg: \", precision_avg)\n",
    "print(\"F1 Avg: \", f1_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemingly the two different input processing methodologies do not create that much of a difference. My guess is that the feature embeddings generated from Word2Vec aren't differentiable/distinct enough (see the comparison between our specific embedding model from our corpus vs the word2vec one) to create a descriptive enough emebdding on which to train our data. I would definetely like to try these out with our own home-brewed embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a: good ol fashioned input from above and training an MLP on dat\n",
    "- reference: https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ofc\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realize that I need to do some data transformations here to make it work, so I retroactively did some mods to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's expand those columns and write it out to a file WITH THE RATINGS for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = pd.DataFrame(train['review_body'].to_list())\n",
    "temp_train['star_rating'] = train['star_rating']\n",
    "\n",
    "temp_test = pd.DataFrame(test['review_body'].to_list())\n",
    "temp_test['star_rating'] = test['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_expanded_data = pd.concat([temp_train, temp_test])\n",
    "full_expanded_data=full_expanded_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write these to files for reading purposes for next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_expanded_data.to_csv('full_expanded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, now for 4a, we're gonna build up the MLP for Multiclass classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports, ofc\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "# from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class readinData(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path, skiprows=1, header=None)\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1] - 1\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = self.y.astype('int')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def split_data(self, n_test=0.20):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_layer = Linear(input_size, 50)\n",
    "        kaiming_uniform_(self.input_layer.weight, nonlinearity='relu')\n",
    "        self.input_activation = ReLU()\n",
    "\n",
    "        self.inner_layer = Linear(50, 10)\n",
    "        kaiming_uniform_(self.inner_layer.weight, nonlinearity='relu')\n",
    "        self.inner_activation = ReLU()\n",
    "\n",
    "        self.output_layer = Linear(10, 5)\n",
    "        xavier_uniform_(self.output_layer.weight)\n",
    "        self.output_activation = Softmax(dim=1)\n",
    " \n",
    "    def forward(self, X):\n",
    "        X = self.input_layer(X)\n",
    "        X = self.input_activation(X)\n",
    "\n",
    "        X = self.inner_layer(X)\n",
    "        X = self.inner_activation(X)\n",
    "\n",
    "        X = self.output_layer(X)\n",
    "        X = self.output_activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    data_set = readinData(path)\n",
    "    train, test = data_set.split_data()\n",
    "\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, model):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        for i, (xs, y_targets) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_med_pred = model(xs)\n",
    "            loss = criterion(y_med_pred, y_targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actuals = list()\n",
    "    for i, (xs, y_targets) in enumerate(test_dl):\n",
    "        y_preds = model(xs)\n",
    "\n",
    "        y_preds = y_preds.detach().numpy()\n",
    "        actual = y_targets.numpy()\n",
    "\n",
    "        y_preds = argmax(y_preds, axis=1)\n",
    "\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        y_preds = y_preds.reshape((len(y_preds), 1))\n",
    "\n",
    "        predictions.append(y_preds)\n",
    "        actuals.append(actual)\n",
    "\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc, actuals, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    y_pred = model(row)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./full_expanded_data.csv\"\n",
    "train_dl, test_dl = prepare_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79954 19989\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.494\n"
     ]
    }
   ],
   "source": [
    "acc, actuals, predictions  = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 accuracy: 0.7286762844849405\n",
      "Class 2 accuracy: 0.3472117083017916\n",
      "Class 3 accuracy: 0.2662192393736018\n",
      "Class 4 accuracy: 0.332245102963335\n",
      "Class 5 accuracy: 0.7904176904176904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(actuals, predictions)\n",
    "acc_array = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for idx, acc_val in enumerate(acc_array):\n",
    "    print(\"Class\", idx+1, \"accuracy:\", acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad for accuracy; some things to improve would be higher epochs and potentially better weight initializations to allow for faster convergence, and ofc more training examples in other categories.\n",
    "<br>\n",
    "But we can move onto the next example now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the train and test from before, concat them, and reset indices just to get the full, pre-converted string reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv', header=0)\n",
    "test = pd.read_csv('./test.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat the vectors to make a 3000 column monstrosity. and yes, pad with 0's apparently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatEmbeddings(model, sentence):\n",
    "        words = sentence.split()\n",
    "        words = [word for word in words if word in model]\n",
    "        return_vec = list()\n",
    "        counter = 0\n",
    "\n",
    "        if len(words) >= 1:\n",
    "            emb_words = model[words]\n",
    "            for idx, word in enumerate(emb_words):\n",
    "                if idx == 10:\n",
    "                    break\n",
    "                return_vec = return_vec + word.tolist()\n",
    "                counter = idx\n",
    "            padding = [0] * (3000 - len(return_vec))\n",
    "            return_vec = return_vec + padding\n",
    "            return return_vec\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ = pd.concat([train, test])\n",
    "full_ =full_.reset_index(drop=True)\n",
    "full_['review_body'] = full_.apply(lambda x: concatEmbeddings(wordvec, x['review_body']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, same issue as before where there's gonna be empty values, but that's a minor issue I'll take a look at if time permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ = full_[full_['review_body'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_=full_.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_thiq = pd.DataFrame(full_['review_body'].to_list())\n",
    "expanded_thiq['star_rating'] = full_['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2991</th>\n",
       "      <th>2992</th>\n",
       "      <th>2993</th>\n",
       "      <th>2994</th>\n",
       "      <th>2995</th>\n",
       "      <th>2996</th>\n",
       "      <th>2997</th>\n",
       "      <th>2998</th>\n",
       "      <th>2999</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.084961</td>\n",
       "      <td>-0.048584</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112305</td>\n",
       "      <td>-0.041016</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>-0.028442</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>-0.099609</td>\n",
       "      <td>0.096191</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044189</td>\n",
       "      <td>0.106934</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>-0.092773</td>\n",
       "      <td>-0.103027</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022827</td>\n",
       "      <td>-0.060547</td>\n",
       "      <td>-0.045166</td>\n",
       "      <td>0.046143</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>-0.049072</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>-0.199219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>-0.028442</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>-0.099609</td>\n",
       "      <td>0.096191</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021729</td>\n",
       "      <td>-0.066406</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>-0.102051</td>\n",
       "      <td>-0.021729</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.029297</td>\n",
       "      <td>-0.206055</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>-0.067383</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>-0.118652</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>-0.052979</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>0.194336</td>\n",
       "      <td>0.112305</td>\n",
       "      <td>-0.052490</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99938</th>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>-0.119141</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>-0.143555</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>-0.030151</td>\n",
       "      <td>-0.119141</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>-0.005981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99939</th>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>-0.067383</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>-0.118652</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>-0.000938</td>\n",
       "      <td>0.031982</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.108887</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99940</th>\n",
       "      <td>-0.225586</td>\n",
       "      <td>-0.019531</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.237305</td>\n",
       "      <td>-0.029297</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>-0.058838</td>\n",
       "      <td>-0.041016</td>\n",
       "      <td>0.052246</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99941</th>\n",
       "      <td>0.200195</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.103027</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>-0.124512</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99942</th>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.084961</td>\n",
       "      <td>-0.048584</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99943 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.109375  0.140625 -0.031738  0.166016 -0.071289  0.015869 -0.003113   \n",
       "1      0.071777  0.208008 -0.028442  0.178711  0.132812 -0.099609  0.096191   \n",
       "2      0.044189  0.106934  0.097168 -0.006042 -0.078125  0.212891  0.160156   \n",
       "3      0.071777  0.208008 -0.028442  0.178711  0.132812 -0.099609  0.096191   \n",
       "4      0.080078  0.104980  0.049805  0.053467 -0.067383 -0.120605  0.035156   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99938  0.016602  0.045654 -0.119141  0.069824 -0.143555  0.104980 -0.030151   \n",
       "99939  0.080078  0.104980  0.049805  0.053467 -0.067383 -0.120605  0.035156   \n",
       "99940 -0.225586 -0.019531  0.090820  0.237305 -0.029297  0.093262 -0.058838   \n",
       "99941  0.200195  0.154297  0.103027  0.008667  0.001183 -0.162109  0.023438   \n",
       "99942  0.109375  0.140625 -0.031738  0.166016 -0.071289  0.015869 -0.003113   \n",
       "\n",
       "              7         8         9  ...      2991      2992      2993  \\\n",
       "0     -0.084961 -0.048584  0.055664  ...  0.112305 -0.041016  0.093262   \n",
       "1     -0.116699 -0.008545  0.148438  ...  0.000000  0.000000  0.000000   \n",
       "2     -0.092773 -0.103027 -0.130859  ... -0.022827 -0.060547 -0.045166   \n",
       "3     -0.116699 -0.008545  0.148438  ... -0.021729 -0.066406  0.055420   \n",
       "4     -0.118652  0.043945  0.030151  ...  0.134766 -0.003601  0.079590   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99938 -0.119141  0.126953 -0.005981  ...  0.000000  0.000000  0.000000   \n",
       "99939 -0.118652  0.043945  0.030151  ...  0.034424 -0.005707 -0.033203   \n",
       "99940 -0.041016  0.052246  0.020020  ...  0.000000  0.000000  0.000000   \n",
       "99941 -0.124512  0.034180 -0.142578  ...  0.000000  0.000000  0.000000   \n",
       "99942 -0.084961 -0.048584  0.055664  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "           2994      2995      2996      2997      2998      2999  star_rating  \n",
       "0     -0.202148 -0.145508  0.082520  0.131836  0.181641 -0.093750            5  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000            5  \n",
       "2      0.046143 -0.051758 -0.049072 -0.046875  0.161133 -0.199219            5  \n",
       "3     -0.102051 -0.021729  0.149414 -0.171875 -0.029297 -0.206055            5  \n",
       "4     -0.052979 -0.133789  0.194336  0.112305 -0.052490 -0.016357            5  \n",
       "...         ...       ...       ...       ...       ...       ...          ...  \n",
       "99938  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000            1  \n",
       "99939 -0.000938  0.031982  0.063477 -0.108887  0.048828 -0.130859            1  \n",
       "99940  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000            1  \n",
       "99941  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000            1  \n",
       "99942  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000            1  \n",
       "\n",
       "[99943 rows x 3001 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_thiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_thiq.to_csv('expanded_thiq.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna read in the data now, then go from there.\n",
    "<br>\n",
    "could also have just...like...not done this and just...used the damn data frame...but fuck it lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./expanded_thiq.csv\"\n",
    "exp_train_dl, exp_test_dl = prepare_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79954 19989\n"
     ]
    }
   ],
   "source": [
    "print(len(exp_train_dl.dataset), len(exp_test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model = MLP(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(exp_train_dl, exp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.415\n"
     ]
    }
   ],
   "source": [
    "exp_acc, exp_actual, exp_preds = evaluate_model(exp_test_dl, exp_model)\n",
    "print('Accuracy: %.3f' % exp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 accuracy: 0.5233714569865738\n",
      "Class 2 accuracy: 0.3436188595408541\n",
      "Class 3 accuracy: 0.31132554596241746\n",
      "Class 4 accuracy: 0.33208582834331335\n",
      "Class 5 accuracy: 0.565743073047859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(exp_actual, exp_preds)\n",
    "acc_array = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for idx, acc_val in enumerate(acc_array):\n",
    "    print(\"Class\", idx+1, \"accuracy:\", acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies are either the same or slightly better. However, the feed-forward neural net approach, while being slightly more difficult to code up, has the most room for fine-tuning regarding hyperparameters. Slight tweaks to epochs or batch size created massive differences in testing accuracy. Given the right model for feature embedding generation, I think the accuracy could really go up from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our favorite place to start: dataproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = pd.read_csv('./train.csv', header=0)\n",
    "test_dset = pd.read_csv('./test.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we've got our data boi back, with just the reviews as words.\n",
    "<br>\n",
    "I believe the idea will be to generate a 20 x 1 x 300 tensor, where 20 is the number of words from a review we will be getting, 1 is the batch size,\n",
    "<br>\n",
    "and 300 is the dimension of each word embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, a function that gets the first 20 words of the review and convert them into tensors of words embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_review_to_tensor(sentence, model):\n",
    "    words = sentence.split()\n",
    "    words = [word for word in words if word in model]\n",
    "    tensor_20 = torch.zeros(20, 1, 300)\n",
    "    \n",
    "    for idx, word in enumerate(words):\n",
    "        if idx == 20:\n",
    "            break\n",
    "        tensor_20[idx][0] = torch.from_numpy(wordvec[word])\n",
    "\n",
    "    return tensor_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have a pandas dataframe with 2 columns now; star rating that is an int and a review that is a 20x1x300 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an aside to actually define the RNN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 20\n",
    "rnn = RNN(300, n_hidden, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a random sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrainingExample(df):\n",
    "    row = df.sample().values.tolist()\n",
    "    rating = row[0][0]\n",
    "    review = row[0][1]\n",
    "    review_tensor = convert_review_to_tensor(review, wordvec)\n",
    "    rating_tensor = torch.tensor([all_categories.index(rating)], dtype=torch.long)\n",
    "    return rating_tensor, review_tensor, review, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to train now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(category, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test out our training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5%  1.6398 i never regret buying anything from amazon this ring is amazing so beautiful  / 5 ✗ (4)\n",
      "10000 10%  1.6297 terrible ankle bracelet broke immediately  / 5 ✗ (1)\n",
      "15000 15%  1.6703 sent this ring back i thought it was a real diamond the mark down was and some odd dollars for cubic zirconia it was white gold but not worth that much sorry / 4 ✗ (1)\n",
      "20000 20%  1.6382 i have a double conch piercing and have been looking for rings that would fit around my ear these are wonderfully made durable comfortable and the seams for the closure are not visible they are droopy but i ended up loving that look even though i was super against it at first  / 1 ✗ (5)\n",
      "25000 25%  1.6590 the price was little less than most alex and ani bracelets and for good reason when i received the bracelet the quality of the metal was garbarge it looked like raw brushed steel and to top it off the lock has a chip out of the bottom of the heart the packaging was fine but the quality of the metal and the bite taking out of the heart were my biggest complains save your money  / 5 ✗ (2)\n",
      "30000 30%  2.0254 my fiance and i wanted to have a low budget wedding since were so young and plan on having a real one a few years down the line so i wanted a beautiful but inexpensive ring with his birthstone on it rather than a diamond this one is perfect i have worn it every day for the past months and the peridot is still shinning brilliantly not a single gem has fallen out a problem i have had with other low cost rings including the very small ones on the sides of the ring i love this ring and i highly recommend it to anyone who is interested  / 2 ✗ (5)\n",
      "35000 35%  1.4533 beautiful earrings lots of compliments if you care about that sort of thing  / 5 ✓\n",
      "40000 40%  1.6679 this is a very pretty sterling silver ring it looks nice on the hand and i have been wearing it for a while now and it still looks shiny and new  / 2 ✗ (5)\n",
      "45000 45%  1.3307 product looked fine from the front but the backside showed a fatal flaw which caused the stone to break off when attempting to wire wrap  / 1 ✗ (2)\n",
      "50000 50%  1.5878 broke in weeks / 5 ✗ (1)\n",
      "55000 55%  1.7095 thick than i expected but ok  / 5 ✗ (3)\n",
      "60000 60%  2.1458 it looks thin in the picture was not expecting it to be so wide but i love it anyways thank you / 1 ✗ (4)\n",
      "65000 65%  1.5698 these earrings are much prettier in person than on screen they shine and appear far more expensive than they are until you get to the clasp it is a little crude and is fragile when using i had to return one pair due to clasp failure but the earrings are so goodlooking that i took a chance on another pair i am glad i did even though the clasp leaves something to be desired  / 3 ✗ (4)\n",
      "70000 70%  0.8757 i love amber and will buy a piece with a stylist look and well made design these earring fit the bill the color is warm and matches other amber pieces the design is solid along with easy clasp one earring loosened up and i had to attach to the clasp but it is fine and i wear them about once a week i would recommend  / 4 ✓\n",
      "75000 75%  1.2152 i love this item i just wished th chain was a little thicker i had been looking for a item like this for some time very beautiful item http www amazon com gp product b f uee ref cm cr rev prod title / 4 ✓\n",
      "80000 80%  1.4467 this bracelet came with scratches and has continued to lose it is finish as i have gently worn it also while i have gained benefit or my minor arthritis from other titanium bracelets call me crazy the phiten stuff works for me and so do some other titanium things i have received no such benefit from this bracelet if it had not scratched further from casual wear i would return it i will say that the bracelet appears to be reasonably sturdy and the clasp works well that is what got it the two stars / 3 ✗ (2)\n",
      "85000 85%  1.2018 straps to hold necklaces broke st time i tried to use it outside is great need to fix the cheap snaps and straps to hold necklaces and this would be a great items outside looks great but the inside snaps and straps for necklaces are a joke  / 2 ✓\n",
      "90000 90%  1.4841 forget the rave reviews you get what you pay for ok for i guess / 1 ✗ (3)\n",
      "95000 95%  1.2399 thought they would be a little bigger but i just love them / 5 ✓\n",
      "100000 100%  1.3168 the flower i received was bigger than i would like it to be i think when they are too big it looks rather gaudy  / 4 ✗ (3)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, review_tensor, review, rating  = randomTrainingExample(train_dset)\n",
    "    # print(category, review_tensor.size())\n",
    "    output, loss = train(category_tensor, review_tensor)\n",
    "    # print(output)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == rating else '✗ (%s)' % rating\n",
    "        print('%d %d%%  %.4f %s / %s %s' % (iter, iter / n_iters * 100, loss, review, guess, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(review_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(review_tensor.size()[0]):\n",
    "        output, hidden = rnn(review_tensor[i], hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_predict(input_line, n_preds=1):\n",
    "\n",
    "    line = input_line.tolist()[0]\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(convert_review_to_tensor(line, wordvec))\n",
    "\n",
    "        topv, topi = output.topk(n_preds, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_preds):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "        \n",
    "        return all_categories[category_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       review_body\n",
      "0                4\n",
      "1                5\n",
      "2                5\n",
      "3                5\n",
      "4                5\n",
      "...            ...\n",
      "19995            3\n",
      "19996            1\n",
      "19997            5\n",
      "19998            3\n",
      "19999            1\n",
      "\n",
      "[20000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "real_preds = test_dset['star_rating']\n",
    "data_lines = pd.DataFrame(test_dset['review_body'])\n",
    "\n",
    "data_lines['review_body'] = data_lines.apply(lambda x: rnn_predict(x, n_preds=1), axis=1)\n",
    "print(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg acc:  0.332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_preds = data_lines['review_body']\n",
    "acc = accuracy_score(real_preds, test_preds)\n",
    "print(\"Avg acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 accuracy: 0.36625\n",
      "Class 2 accuracy: 0.07425\n",
      "Class 3 accuracy: 0.22275\n",
      "Class 4 accuracy: 0.10825\n",
      "Class 5 accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(real_preds, test_preds)\n",
    "acc_array = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for idx, acc_val in enumerate(acc_array):\n",
    "    print(\"Class\", idx+1, \"accuracy:\", acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Accuracy is...alright...but hell it's better than 0 I guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b\n",
    "- Now, let's try a gated RNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.GRUCell(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.GRUCell(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 20\n",
    "grnn = GRNN(300, n_hidden, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train da grnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grnn_train(category, line_tensor):\n",
    "    hidden = grnn.initHidden()\n",
    "\n",
    "    grnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = grnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category)\n",
    "    loss.backward()\n",
    "\n",
    "    for p in grnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5%  1.5079 just as expected / 5 ✓\n",
      "10000 10%  1.6036 this was pricey for the type of jewelry it is but it is artsy and different and i like that the picture would have you believe the closure is directly degrees across from the pendant drop but it is not the pendant drop is actually about to the left of center i have a neck and there is not a lot of play for this necklace to hang it fits pretty snugly when i wear this i arrange the pendant to be center front on me and just wear the closure off center in the back the guitar pick is positioned too high up near my collarbone to hang noticeably despite its size i like this piece for the uniqueness of it it is great quality based on the durability of it and the charms used are securely attached and not one of the charms are flimsy at all  / 3 ✗ (4)\n",
      "15000 15%  1.5221 beautiful and exactly as advertised  / 5 ✓\n",
      "20000 20%  1.7157 this owl cuff is great i bought this item as a birthday gift the cuff is smaller than it appears in the picture width wise other than that its great  / 3 ✗ (4)\n",
      "25000 25%  1.7103 appearance looks exactly like the picture fits perfectly too durability i have had this for about a month or so and the ring has not become tarnished or discolored it is still the same color and i wear this product every day when i wash my hands i take it off to take a shower though i have this problem when i buy rings that my finger turns green at the area where the ring sits but this ring has not made my finger turn green at all if you have the same problem and are worried about that do not be i would definitely recommend this product to others  / 2 ✗ (5)\n",
      "30000 30%  1.8227 purchased as gift sized as shown only wanted bible no crosses or other symbols so it suited my purpose sufficiently  / 3 ✗ (4)\n",
      "35000 35%  1.6173 i like it its big but i am ok with it the material is more plastic than anything  / 5 ✗ (2)\n",
      "40000 40%  1.5055 did not like them as like other reviewers have said these are uncomfortable to wear they are rather pretty but not quite what i like also agree that the closing of the hoop part is poorly made / 3 ✗ (2)\n",
      "45000 45%  1.5856 one eyes was missing from one of the owls i need to return them other than that they are really cute  / 4 ✗ (1)\n",
      "50000 50%  1.6081 the earrings are a little ti short an pinch my ear when i try to wear them an it took longer to recive them than it should have i was not pleased with that at all  / 1 ✗ (3)\n",
      "55000 55%  1.4911 after reading the description i misunderstood that the clear in the description meant the actual ring i thought the stud was clear and the actual ring was silver as it looks in the picture i was disappointed and will not wear this in public as it does look fake and could never be mistaken as a real piercing if that what you are aiming for i had my nose pierced but had to take it out for interviews and it closed so i was looking for something more realistic  / 2 ✓\n",
      "60000 60%  1.5526 only returned for non opal flatness appeared to be an opal defect where it was not flat but an indentation on one earring otherwise solid and as described wonderful was a fluke defect in my order  / 3 ✗ (2)\n",
      "65000 65%  1.5252 it is really a brown bead not at all red as stated in description it is still a very nice bracelet however  / 1 ✗ (4)\n",
      "70000 70%  1.4610 this was almost impossible to put on by yourself the charms although pretty all keep falling under the wrist because there is nothing to keep them in place so what stays on the top of your wrist is the plain bracelet band not only does not it look so good with the charms under the wrist but it is really uncomfortable i just do not get who could wear this  / 2 ✓\n",
      "75000 75%  1.5578 i really like the size of these earrings and the clasp happens to be my favorite type of hoop clasp but the stationary part of the clasp was bent back and the space for the hinged piece to fit between has too wide of an opening and therefore does not stay closed i have to be creative and use a post back to keep from losing the earrings for the price the earrings were too much trouble to send back but works well with my creative way of keeping them on my ear  / 4 ✗ (2)\n",
      "80000 80%  1.7279 it a bit small but it will do i can used it where i want it for it has to be longer maybe inch more you have a bless day ps the chain is made well  / 3 ✗ (5)\n",
      "85000 85%  1.9319 these earrings are what i have been looking for for a long time could always find the single or double ball but never the three balls and they are beautiful although they are very inexpensive they look stunning  / 3 ✗ (5)\n",
      "90000 90%  1.6574 love love love this ring only dislike is that the stone is a lot lighter than pictured still beautiful though  / 5 ✗ (4)\n",
      "95000 95%  1.5534 very beautiful but broke when adjusting size / 5 ✗ (1)\n",
      "100000 100%  1.6725 bought this for my husband and it loves it great true to size fit  / 5 ✗ (4)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, review_tensor, review, rating  = randomTrainingExample(train_dset)\n",
    "    output, loss = grnn_train(category_tensor, review_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == rating else '✗ (%s)' % rating\n",
    "        print('%d %d%%  %.4f %s / %s %s' % (iter, iter / n_iters * 100, loss, review, guess, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grnn_evaluate(review_tensor):\n",
    "    hidden = grnn.initHidden()\n",
    "\n",
    "    for i in range(review_tensor.size()[0]):\n",
    "        output, hidden = grnn(review_tensor[i], hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grnn_predict(input_line, n_preds=1):\n",
    "    line = input_line.tolist()[0]\n",
    "    with torch.no_grad():\n",
    "        output = grnn_evaluate(convert_review_to_tensor(line, wordvec))\n",
    "\n",
    "        topv, topi = output.topk(n_preds, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_preds):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            predictions.append([value, all_categories[category_index]])\n",
    "        \n",
    "        return all_categories[category_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       review_body\n",
      "0                2\n",
      "1                5\n",
      "2                5\n",
      "3                5\n",
      "4                3\n",
      "...            ...\n",
      "19995            5\n",
      "19996            2\n",
      "19997            5\n",
      "19998            5\n",
      "19999            5\n",
      "\n",
      "[20000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "real_preds = test_dset['star_rating']\n",
    "g_data_lines = pd.DataFrame(test_dset['review_body'])\n",
    "\n",
    "g_data_lines['review_body'] = g_data_lines.apply(lambda x: grnn_predict(x, n_preds=1), axis=1)\n",
    "print(g_data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg GRNN acc:  0.2287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "g_test_preds = g_data_lines['review_body']\n",
    "acc = accuracy_score(real_preds, g_test_preds)\n",
    "print(\"Avg GRNN acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 accuracy: 0.09825\n",
      "Class 2 accuracy: 0.313\n",
      "Class 3 accuracy: 0.13475\n",
      "Class 4 accuracy: 0.0985\n",
      "Class 5 accuracy: 0.499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(real_preds, g_test_preds)\n",
    "acc_array = matrix.diagonal()/matrix.sum(axis=1)\n",
    "for idx, acc_val in enumerate(acc_array):\n",
    "    print(\"Class\", idx+1, \"accuracy:\", acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it seems our accuracy got worse. However, there are a few reasons this might be the case. the main issue could be the training hyperparameters, ie number of examples of each category, the embedding method, the learning rate(s), the batch size, etc...\n",
    "<br>\n",
    "I think if we tried tuning these parameters we might have some luck with this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "544",
   "language": "python",
   "name": "544"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
